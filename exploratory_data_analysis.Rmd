---
title: "Intersecting soil point observations with environmental covariates"
author: "OchiengHosea"
date: "10/12/2020"
output: html_document
---
```{r}
library(ithir)
data(HV_subsoilpH)
str(HV_subsoilpH)
```
As you will note, there are 506 observations of soil pH. These data are associated with a spatial coordinate and also have associated environmental covariate data that have been intersected with the point data. The environmental covariates have been sourced from a digital elevation model and Landsat 7 satellite data. For the demonstration purposes of the exercise, we will firstly remove this already intersected data and start fresh - essentially this is an opportunity to recall earlier work on dataframe manipulation and indexing.
```{r}
# round pH data to 2 decimal places
HV_subsoilpH$pH60_100cm <- round(HV_subsoilpH$pH60_100cm, 2)

# remove already intersected data
HV_subsoilpH <- HV_subsoilpH[, 1:3]

# add an id column
HV_subsoilpH$id <- seq(1, nrow(HV_subsoilpH), by = 1)

# re-arrange order of columns
HV_subsoilpH <- HV_subsoilpH[, c(4, 1, 2, 3)]

# Change names of coordinate columns
names(HV_subsoilpH)[2:3] <- c("x", "y")
```

Also in the ithir package are a collection of rasters that correspond to environmental covariates that cover the extent of the just loaded soil point data. These can be loaded using the script:

```{r}
data(hunterCovariates_sub)
hunterCovariates_sub
```
While the example is a little contrived, it is useful to always determine whether or not the available covariates have complete coverage of the soil point data. This might be done with the following script which will produce a map like in the figure below.

```{r}
plot(hunterCovariates_sub[["Elevation"]], main = "Hunter Valley elevation map with overlayed point locations")
# coordinates(HV_subsoilpH) <- ~x + y
# plot(HV_subsoilpH, add=T)
```
With the soil point data and covariates prepared, it is time to perform the intersection between the soil observations and covariate layers using the script:

```{r}
coordinates(HV_subsoilpH) <- ~x + y
DSM_data <- extract(x=hunterCovariates_sub, y=HV_subsoilpH, sp=1, method = "simple")
```
The extract function is quite useful. Essentially the function ingests the rasterStack object, together with the SpatialPointsDataFrame object HV_subsoilpH. The sp parameter set to 1 means that the extracted covariate data gets appended to the existing SpatialPointsDataFrame object. While the method object specifies the extraction method which in our case is simple which likened to get the covariate value nearest to the points i.e it is likened to drilling down.

A good practice is to then export the soil and covariate data intersect object to file for later use. First we convert the spatial object to a data.frame, then export as a comma separated file.

```{r}

DSM_data <- as.data.frame(DSM_data)
write.csv(DSM_data, "hunterValley_SoilCovariates_pH.csv", row.names = FALSE)
```
# Some exploratory data analysis

```{r}
library(sp)
library(raster)
library(gstat)
library(nortest)
library(fBasics)
library(ggplot2)
```

# Some summary statistics
```{r}
hv.dat <- read.csv("hunterValley_SoilCovariates_pH.csv")
str(hv.dat)
```
```{r}
round(summary(hv.dat$pH60_100cm), 1)
```
since mean and median are close, we can assume that the data does not deviate too much from the normal
```{r}
sampleSKEW(hv.dat$pH60_100cm)
sampleKURT(hv.dat$pH60_100cm)
ad.test(hv.dat$pH60_100cm)
par(mfrow = c(1,2))
hist(hv.dat$pH60_100cm)
qqnorm(hv.dat$pH60_100cm, plot.it = TRUE, pch = 4, cex = 0.7)
qqline(hv.dat$pH60_100cm, col = "red", lwd = 2)
```
Another useful exploratory test is to visualize the data in its spatial context. Mapping the point locations with respect to the target variable by either altering the size or color of the marker gives a quick way to examine the target soil attribute spatial variability. Using the ggplot2 package, we could create the plot as shown below.

```{r}
ggplot(hv.dat, aes(x = x, y = y)) + geom_point(aes(size = pH60_100cm))
```
Spatial distribution of points in the Hunter Valley for the soil pH data at the 60-100cm depth interval. Size of the markings is relative to the pH measurement reading.


# Inverse Distance weighted interpolation
Functions for IDW interpolation and kriging are found in the gstat package

To initiate these interpolation methods, we first need to prepare a grid of points upon which the interpolation will be made

This can be done by either extracting the cordinates from either of the 25m resolution rasters we have for the hunter valley.

To extract pixel the pixel point coordinates from raster, we do the following using the `hunterCovariates_sub` raster stack

```{r}
tempD <- data.frame(cellNos = seq(1:ncell(hunterCovariates_sub)))
tempD$vals <- getValues(hunterCovariates_sub)
tempD <- tempD[complete.cases(tempD), ]
cellNos <- c(tempD$cellNos) # getting cell numbers that have data, whose values are not NA
gXY <- data.frame(xyFromCell(hunterCovariates_sub, cellNos, spatial = FALSE))
```
Using the idw function from gstat we fit the formula as below. We need to specify the observed data, their spatial locations, and the spatial locations of the points we want to interpolate onto. The idp parameter allows you to specify the inverse distance weighting power. The default is 2, yet can be adjusted if you want to give more weighting to points closer to the interpolation point. As we can not evaluate the uncertainty of prediction with IDW, we can not really optimize this parameter.

```{r}
IDW.pred <- idw(hv.dat$pH60_100cm ~ 1, locations = ~x + y, data = hv.dat, newdata = gXY, idp = 2)
```
Plotting the resulting map below can be done using the following script

```{r}
IDW.raster.p <- rasterFromXYZ(as.data.frame(IDW.pred[, 1:3]))
plot(IDW.raster.p)
```

# Krigging
For soil science it is more common to use krigging for the reasons that we are able to formally define the spatial relationships in our data and get an estimate of the prediction uncertainity.

For soil science it is more common to use kriging for the reasons that we are able to formally define the spatial relationships in our data and get an estimate of the prediction uncertainty. As mentioned before this is done using a variogram. Variograms measure the spatial auto-correlation of phenomena such as soil properties (Pringle and McBratney 1999). The average variance between any pair of sampling points (calculated as the semi-variance) for a soil property S at any point of distance h apart can be estimated by the formula:

$\gamma(h)=\frac{1}{2m(h)}\sum_{i=1}^{m(h)}\{s(x_{i})-s(x_{i}+h)\}^2$

where Î³(h) is the average semi-variance, m is the number of pairs of sampling points, s is the value of the attribute under investigation, x are the coordinates of the point, and h is the lag (separation distance of point pairs). Therefore, in accordance with the law of geography, points closer together will show smaller semi-variance (higher correlation), whereas pairs of points farther away from each other will display larger semi-variance. A variogram is generated by plotting the average semi-variance against the lag distance. Various models can be fitted to this empirical variogram where four of the more common ones are the linear model, the spherical model, the exponential model, and the Gaussian model. Once an appropriate variogram has been modeled it is then used for distance weighted interpolation (kriging) at unvisited locations.

First, we calculate the empirical variogram i.e calculate the semi-variances of all point pairs in our data set. Then we fit a variogram model (in this case we will use a spherical model). To do this we need to make some initial estimates of this models parameters; namely, the nugget, sill, and range. The nugget is the very short-range error (effectively zero distance) which is often attributed to measurement errors. The sill is the limit of the variogram (effectively the total variance of the data). The range is the distance at which the data are no longer auto-correlated. Once we have made the first estimates of these parameters, we use the fit.variogram function for their optimization. The width parameter of the variogram function is the width of distance intervals into which data point pairs are grouped or binned for semi variance estimates as a function of distance. An automated way of estimating the variogram parameters is to use the autofitVariogram function from the automap package. For now we will stick with the gstat implementation.

```{r}
vgm1 <- variogram(pH60_100cm ~ 1, ~x + y, hv.dat, width = 100, cutoff = 3000)
mod = vgm(psill = var(hv.dat$pH60_100cm), "Exp", range = 3000, nugget = 0)
model_1 = fit.variogram(vgm1, mod)
model_1
```
The plot in Figure below shows both the empirical variogram together with the fitted variogram model line.
```{r}
plot(vgm1, model=model_1)
```
The variogram is indicating there shows there is some spatial structure in the data up to around 500m. Using this fitted variogram model lets perform the kriging to make a map, but more importantly look at the variances associated with the predictions too. Here we use the krige function, which is not unlike using idw function, except that we have the variogram model parameters as additional information.
```{r}
krig.pred <- krige(hv.dat$pH60_100cm ~ 1, locations = ~x + y, data = hv.dat, newdata = gXY, model = model_1)

# e can make the maps as we did before, but now we can also look at the variances of the predictions too.

par(mfrow = c(2, 1))
krig.raster.p <- rasterFromXYZ(as.data.frame(krig.pred[, 1:3]))
krig.raster.var <- rasterFromXYZ(as.data.frame(krig.pred[, c(1:2, 4)]))
plot(krig.raster.p, main = "ordinary krigging predictions")
plot(krig.raster.var, main = "ordinary krigging variance")
```
Correlative data analysis
Understanding the geostatistical properties of the target soil variable of interest is useful in its own right. However, it is also important to determine whether there is further spatial relationships in the data that can be modeled with environmental covariate information. Better still is to combine both spatial model approaches together (more of which will be discussed later on about this).

Ideally when we want to predict soil variables using covariate information is that there is a reasonable correlation between them. We can quickly assess these using the base cor function, for which we have used previously.

```{r}
cor(hv.dat[, c("Terrain_Ruggedness_Index", "AACN", "Landsat_Band1", "Elevation", 
    "Hillshading", "Light_insolation", "Mid_Slope_Positon", "MRVBF", "NDVI", "TWI", 
    "Slope")], hv.dat[, "pH60_100cm"])
```

